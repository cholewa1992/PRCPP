\documentclass{ituhandin}

\coursename{Practical Concurrent and Parallel Programming}
\fullname{Jacob B. Cholewa}
\when{January 2016}
\initials{jbec}
\coursecode{PRCPP}

\begin{document}
\maketitlepage
\signpage

\chapter{} %1

\section{}
The output for \texttt{TestLocking0.java} clearly indicates that it is not thread-safe.
\begin{lstlisting}[language={}, frame={}]
mac610262:src jbec$ java TestLocking0
Sum is 1505632.000000 and should be 2000000.000000
mac610262:src jbec$ java TestLocking0
Sum is 1490208.000000 and should be 2000000.000000
mac610262:src jbec$ java TestLocking0
Sum is 1497894.000000 and should be 2000000.000000
mac610262:src jbec$ java TestLocking0
Sum is 1505498.000000 and should be 2000000.000000
\end{lstlisting}

The actual sum deviates from the expected sum leading me to believe that a race condition occurs in the code.

\section{}
The problem is that while the \texttt{addInstance} method locks the object instance, \texttt{addStatic} locks the class. Hence the field \texttt{sum} is guarded by multiple locks. This allows for multiple threads to simultaneously access the \texttt{sum} variable, therefore not upholding mutual exclusion, potentially causing the race condition making it not threadsafe.

\section{}
A simple solution is to change \texttt{addInstance} so that it is guarded by the class lock used by the static synchronized methods
\begin{lstlisting}[frame={}]
public void addInstance(double x) {
    synchronized(Mystery.class){
        sum += x;
    }
}
\end{lstlisting}
This now ensures mutual exclusion as \texttt{sum} is now guarded by the same lock. Rerunning the code shows that the expected result and the actual result are now the same.

\begin{lstlisting}[language={}, frame={}]
mac610262:src jbec$ java TestLocking0
Sum is 2000000.000000 and should be 2000000.000000
mac610262:src jbec$ java TestLocking0
Sum is 2000000.000000 and should be 2000000.000000
mac610262:src jbec$ java TestLocking0
Sum is 2000000.000000 and should be 2000000.000000
mac610262:src jbec$ java TestLocking0
Sum is 2000000.000000 and should be 2000000.000000
\end{lstlisting}

\chapter{} %2
\section{}
The simplest way would be to make a synchronized version that guards \texttt{items} and \texttt{size} with an instance lock. This would ensure safe concurrent access to the arraylist.
\section{}\label{sec:lock}
While the na√Øve approach described above makes the arraylist threadsafe, it does not allow parallel access and thus doesn't scale. Actually I expect the synchronized version to perform significantly worse when used by many threads compared to only a single thread.
\section{}
A simple answer to why the purposed pattern is not threadsafe is found in the sample given in the assignment. The example clearly shows that both \texttt{add} and \texttt{set} accesses \texttt{items} and \texttt{size}. As the methods uses different locks, concurrent access to \texttt{items} and \texttt{size} can occur making it not threadsafe.

\moreFancyQuote{When thread $A$ executes a synchronized block, and subsequently thread $B$ enters a synchronized block guarded by the same lock, the values of variables that were visible to $A$ prior to releasing the lock are guaranteed to be visible to $B$ upon acquiring the lock.}{\citet[p. 37]{goetz2006java}}
Because the methods uses different locks, visibility is also not guaranteed between threads.

\section{}
While it is possible that a version might exist that makes this threadsafe, it will still require mutual exclusion when at least writing to \texttt{items} and \texttt{size}. I don't see many other (simple) ways than to fully lock both \texttt{items} and \texttt{size} when accessed. Thus it won't make much sense to have a lock for the methods if we either way have to lock the only two shared fields. Then we could as well just only lock those instead.

\chapter{} %3
\section{}
The \texttt{totalSize} field can be made threadsafe by either using an \texttt{AtomicInteger} or by having \texttt{totalSize} guarded by a static lock object. The following snippet shows how it would be implemented in the code using an \texttt{AtomicInteger}

\begin{lstlisting}[frame={}]
private static AtomicInteger totalSize = new AtomicInteger();

public boolean add(double x) {
    if (size == items.length) {
        ...
    }
    items[size] = x;
    size++;
    totalSize.incrementAndGet();
    return true;
}

public static int totalSize() {
    return totalSize.get();
}
\end{lstlisting}

\section{}
The \texttt{allLists} field can be make threadsafe by guarding it with a static lock object. It can be implemented in code in following way.
\begin{lstlisting}[frame={}]
private static HashSet<DoubleArrayList> allLists = new HashSet<>();
private static Object ListsLock = new Object();

public DoubleArrayList() {
    synchronized(ListsLock){
        allLists.add(this);
    }
}

public static HashSet<DoubleArrayList> allLists() {
    synchronized(ListsLock){
        return allLists;
    }
}
\end{lstlisting}

\chapter{} %4
\section{}
\begin{lstlisting}[caption=Implemented code for the Sorting stage]
static class SortingStage implements Runnable {
    private final BlockingDoubleQueue in;
    private final BlockingDoubleQueue out;
    private final double[] heap; 
    private int itemCount;
    private int heapSize = 0;

    public SortingStage(BlockingDoubleQueue in, BlockingDoubleQueue out, int capacity, int itemCount){
        this.in = in;
        this.out = out;
        this.itemCount = itemCount;
        heap = new double[capacity];
    }

    public void run() { 
        while(itemCount > 0){
            double x = in.take();
            if(heapSize < heap.length){ //heap not full, put x into it
                heap[heapSize++] = x;
                DoubleArray.minheapSiftup(heap, heapSize-1, heapSize-1);
            } else if (x <= heap[0]){ //x is small, forward
                out.put(x);
                itemCount--;
            } else { //forward least, replace with x
                double least = heap[0];
                heap[0] = x;
                DoubleArray.minheapSiftdown(heap,0,heapSize-1);
                out.put(least);
                itemCount--;
            }
        }
    }
}
\end{lstlisting}
See the fully implemented \texttt{SortingPipeline.java} in appendix \todo{make ref}
\newpage
\section{}
\begin{lstlisting}[caption=Implemented code for setting up and starting stages]
private static void sortPipeline(double[] arr, int P, BlockingDoubleQueue[] queues) {
    int n = arr.length / P;

    //Initializing the sorting stages
    Thread[] threads = new Thread[P+2];
    for(int i = 1; i <= P; i++){
        threads[i-1] = new Thread(new SortingStage(queues[i-1], queues[i], n, arr.length+(P-i)*n)); 
    }

    //Initializing the drain
    threads[P] = new Thread(new SortedChecker(arr.length, queues[P]));

    //Initializing the source. The source is purposefully last in the array so that it will be started lastly.
    threads[P+1] = new Thread(new DoubleGenerator(arr, arr.length, queues[0]));

    //Starting the stages
    for(int i = 0; i < threads.length; i++){
        threads[i].start();
    }

    //Joining the stages
    for(int i = 0; i < threads.length; i++){
        try{ threads[i].join(); }
        catch(InterruptedException e){ throw new RuntimeException(e); }
    }
}
\end{lstlisting}

\chapter{} %5
\section{} %wrapper
\begin{lstlisting}[caption=Implemented code for wrapping \texttt{ArrayBlockingQueue}]
class WrappedArrayDoubleQueue implements BlockingDoubleQueue{
    private final ArrayBlockingQueue<Double> queue;

    public WrappedArrayDoubleQueue(){
        this.queue = new ArrayBlockingQueue<Double>(50);
    }

    public WrappedArrayDoubleQueue(int capacity){
        this.queue = new ArrayBlockingQueue<Double>(capacity);
    }

    public void put(double item){
        try{ queue.put(item); }
        catch(InterruptedException e){ throw new RuntimeException(e); }
    }

    public double take(){
        try{ return queue.take(); }
        catch(InterruptedException e){ throw new RuntimeException(e); }
    }
}
\end{lstlisting}
\section{} %with 40
The result of running the code results in a sorted list of elements as expected. The program terminated by itself indicating that all the stages ended as desired.
\begin{lstlisting}[language={},frame={}]
mac610262:src jbec$ java SortingPipeline
0.1 1.1 2.1 3.1 4.1 5.1 6.1 7.1 8.1 9.1 10.1 11.1 12.1 13.1 14.1 15.1 16.1 17.1 18.1 19.1 20.1 21.1 22.1 23.1 24.1 25.1 26.1 27.1 28.1 29.1 30.1 31.1 32.1 33.1 34.1 35.1 36.1 37.1 38.1 39.1
\end{lstlisting}
\section{}\label{sec:sortingpipelinetests}

\todo{write discussion}

\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T14:45:02+0100
Sorting pipe    125.9 ms    1.71    4
\end{lstlisting}
\chapter{} %6
\section{}

The following queue implementation is a queue inspired by the one presented in the slides from lecture 5 (OneItemQueue), but instead using a cyclic array implemented with a normal array and a \texttt{head} and \texttt{tail} pointer. The pointers will loop back to zero if they get out of bound providing the cyclic behavior.

\begin{lstlisting}[caption= Implementation of the \texttt{BlockingNDoubleQueue} blocking fixed size queue]
class BlockingNDoubleQueue implements BlockingDoubleQueue{
    private final double[] arr = new double[50];
    private int head = 0, tail = 0, count = 0;

    public synchronized void put(double item){
        while(count == arr.length){
            try{ this.wait(); }
            catch(InterruptedException exn) { }
        }

        arr[tail] = item;
        tail = ++tail == arr.length ? 0 : tail;
        count++;
        this.notify();
    }

    public synchronized double take(){
        while(count == 0){
            try{ this.wait(); }
            catch(InterruptedException exn) { }
        }

    double item = arr[head];
        head = ++head == arr.length ? 0 : head;
        count --;
        this.notify();
        return item;
    }
    }
\end{lstlisting}

\section{}
The queue presented above is threadsafe as the only two methods, \texttt{put} and \texttt{take} is synchronized. Thus  the array, the two pointers and the counter is guarded by the instance object meaning that only one thread can access them at a time. A thread can be blocked, forced to wait, if the queue is either empty or full. The thread will be forced release the lock and wait until the blocking condition is no longer met. Then the thread will again try to acquire the lock before continuing. This thereby follow the monitor pattern making it threadsafe. 

\section{}
Running the pipeline with the \texttt{BlockingNDoubleQueue} yields following results.
\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T16:52:52+0100
Sorting pipe    470.4 ms    36.56   2
\end{lstlisting}
These results are quite interesting as it becomes clear that the new queue is a performance bottleneck compared to the results from \ref{sec:sortingpipelinetests} where these results are almost 4 times slower. This might be due to that fact that this queue allows for no parallelism plausibly causing threads to be often blocked by each other.

\chapter{} %7
\section{}
This queue implementation uses a linkedlist to make it unbounded. This means, in contrast to the previous queue, that it can hold as unlimited number of items (while available memory still, of course, is a limitation). This queue is also blocking forcing threads to wait if no elements is available in the queue.
\begin{lstlisting}[caption= Implementation of the \texttt{UnboundedDoubleQueue} blocking queue]
class UnboundedDoubleQueue implements BlockingDoubleQueue{

    public Node head;
    public Node tail;

    public UnboundedDoubleQueue(){
        Node n = new Node(0,null);
        tail = head = n;
    }

    public synchronized void put(double item){
        tail.next = new Node(item,null); //Setting next
        tail = tail.next; //Moving tail

        this.notify(); //Notifying a thread waiting for elements
    }

    public synchronized double take(){
        while(head.next == null){
            try{ this.wait(); }
            catch(InterruptedException exn) { }
        }

        Node first = head;
        head = first.next;
        return head.value;
    }

    class Node{
        public Node next;
        public final double value;

        public Node(double value, Node next){
            this.next = next;
            this.value = value;
        }
    }
}
\end{lstlisting}
\section{}
This implementation also follows the monitor pattern and is therefore threadsafe. In this queue, producers are never forced to wait as the queue is unbounded. Only consumers wait if there is no more elements to consume.
\section{}
\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T18:01:39+0100
Sorting pipe    262.1 ms    14.29   2
\end{lstlisting}

This queue performs significantly better than the previous. In the previous queue the \texttt{DoubleGenerator}, which will produce faster then the sort stages can consume, was forced to stop and wait for the queue to become non-full. In this queue the \texttt{DoubleGenerator} is never forced to wait which I suspect to be the reason for the vast speedup.

\chapter{} %8
\section{} %8.1
\begin{lstlisting}[caption= Implementation of the \texttt{UnboundedDoubleQueue} blocking queue]
class NoLockNDoubleQueue implements BlockingDoubleQueue{

    private final double[] arr = new double[50];
    private volatile int head = 0, tail = 0;

    public void put(double item){
        while(tail - head == arr.length){} //Spin
        arr[tail % arr.length] = item;
        tail++;
    }

    public double take() { 
        while(tail - head == 0){} //Spin
        double item = arr[head % arr.length];
        head++;
        return item; 
    }
}
\end{lstlisting}
\section{} %8.2

I use volatile and final in two lines. Firstly the double array used for storing elements in the queue is final. This is due to the fact that 1) it will never change, and 2) the final keyword ensures visibility. The volatile keyword is used when declaring \texttt{head} and \texttt{tail}. This is to ensure visibility. 

\section{} %8.3
\texttt{wait} and \texttt{notify} can only be used within synchronized blocks guarded by the same lock; and for good reason. Consider this simple example \footnote{Inspired by \url{http://stackoverflow.com/questions/2779484/why-must-wait-always-be-in-synchronized-block}}.

\begin{lstlisting}[frame={}]
public void produce(double item){
    queue.put(item);
    notify();
}

public double consume(){
    while(queue.isEmpty())
        wait();
    return queue.take();
}
\end{lstlisting}
For this example it might be the case that: 
\begin{enumerate}
        \item Thread $A$ calls consume. The consumer goes into the while loop because the buffer is empty.
        \item Before Thread $A$ calls \texttt{wait}, Thread $B$ executes produce and calls \texttt{notify}.
        \item Now Thread $A$ calls \texttt{wait}, however, it might happen that \texttt{notify} is never called again because
        \begin{enumerate}
            \item $B$ finished, and $A$ therefore stays asleep, even though the queue is no longer empty. 
            \item $B$ is waiting for $A$ thus causing a deadlock.
        \end{enumerate}
\end{enumerate}
\section{} %8.4
The construct of this queue is such that only a single thread will call \texttt{put}, and another will call \texttt{take}. These are the only two threads calling the methods. Because both methods depend on knowing both \texttt{head} and \texttt{tail} to calculate if the queue is full or empty, visibility is required. 
The two pointers is only written from one thread each; Namely, \texttt{head} is written to by the thread calling \texttt{take}, while tail is written to by the thread calling \texttt{put}. Therefore visibility is strong enough to ensure threadsafe parallel access to the two pointers. 

Concurrent access to the same index of the double array can never happen. This is due to the fact that if $tail - head == 0$, then they will point to the same index, but only \texttt{put} can access the index due to the spin loop in \texttt{take}. In the same manor, if $tail - head == arr.length$, then they will point to the same index, but only \texttt{take} can access the index due to the spin loop in \texttt{put}.

Visibility of the elements put into and removed from the double array is guaranteed because read and writing to volatile fields have the same guarantee as locking and unlocking, namely that everything $A$ did in or prior to a read/write of a volatile field is visible to $B$ when performing a read/write to the same field.  

Therefore the queue is threadsafe, but of course only under the constraint that only one thread calls \texttt{take} and another only calls \texttt{put}. If more than these two thread call the queue, then it is not threadsafe.

\section{} %8.5
I tried three different scenarios
\begin{enumerate}
    \item Removed volatile from \texttt{head}
    \item Removed volatile from \texttt{tail}
    \item Removed volatile from both
\end{enumerate}

The first one was to remove volatile from \texttt{head}. This resulted in following output:

\begin{lstlisting}[language={},frame={}]
mac610262:src jbec$ java SortingPipeline
...
Elements out of order: 2062.10 before 2062.10
Elements out of order: 3461.10 before 3461.10
Elements out of order: 10689.1 before 10689.1
Elements out of order: 16950.1 before 16950.1
Elements out of order: 19756.1 before 19756.1
Elements out of order: 20723.1 before 20723.1
Elements out of order: 22962.1 before 22962.1
Elements out of order: 33233.1 before 33233.1
Elements out of order: 38267.1 before 38267.1
Elements out of order: 38380.1 before 38380.1
Elements out of order: 55126.1 before 55126.1
Elements out of order: 79719.1 before 79719.1
...
\end{lstlisting}

It is clear to see that some elements was emitted more than once as the input array contains no duplicates. What is likely happening the  \texttt{head} increment is not visible to the other thread. Thus the \texttt{put} method is supposed to spin when the array is full, it might just happen that it override another element with an element already added once before.

The exact same behavior is observed when the \texttt{tail} is not volatile. This might might be due to the fact that if the thread calling \texttt{take} does not see the \texttt{tail} increment, then it might very well be that the method returns an item even though the queue is empty, which would be an item it had already returned, although it was in fact suppose to spin.

Lastly, removing volatile from both fields make the code go into an instant deadlock probably because both threads is spinning waiting for each other.


\section{} %8.6
\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T18:56:06+0100
Sorting pipe    43.9 ms     1.52    8
\end{lstlisting}
\section{} %8.7


The results with $P = 2$.
\begin{lstlisting}[language={},frame={}, gobble=2]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T20:49:19+0100
Sorting pipe    34.1 ms     0.48    8
\end{lstlisting}


The results with $P = 8$
\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T20:56:08+0100
Sorting pipe    5855.0 ms   151.62  2
\end{lstlisting}

While the execution with $P = 2$ performed better than $P = 4$, the execution with $P = 8$ performed very poorly.

First of all, the bad performance of $P = 8$ is due to the fact that we now have more stages than cores in my machine. Because every stage is not running in parallel, and the stages are being scheduled in and out, because the stages spend most of their time at halt because they quickly consumed what was left in the queue, or fill up the outgoing queue, and then spend the remaining time waiting before getting descheduled. This is of course very inefficient. 

The fact that $P = 2$ performs better than $P = 4$ I think is due to the fact that there is less overhead to the computations. Passing the numbers from queue to queue and all the time reorganizing the local heap is a costly affair. Running with $P = 1$ was sightly slower than $P = 2$ with $39ms$.

To confirm the hypothesis about $P = 8$ I executed the code to get the results for $P = 6$. I'm not expecting any drastic performance decrease because $6+2$ is the number of cores in my computer. 

\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T20:54:58+0100
Sorting pipe    47.2 ms     1.54    8
\end{lstlisting}

The results shows that $P = 6$ is almost as fast as $P = 4$.

\chapter{} %9
\section{}
This is the exact version as given in exercise 12 except for the one \texttt{return null} subtituted with a \texttt{continue} in the take method.
\begin{lstlisting}[caption=Implementation of the \texttt{MSUnboundedDoubleQueue}]
class MSUnboundedDoubleQueue implements BlockingDoubleQueue{
    private final AtomicReference<Node> head, tail;
    public MSUnboundedDoubleQueue(){
        Node sentinal = new Node(0,null);
        head = new AtomicReference<Node>(sentinal);
        tail = new AtomicReference<Node>(sentinal);
    }
    public void put(double item){
        Node node = new Node(item,null);
        while(true){
            Node last = tail.get(), 
                 next = last.next.get();
            if(last == tail.get()){
                if(next == null){
                    if(last.next.compareAndSet(next,node)){
                        tail.compareAndSet(last,node);
                        return;
                    }
                } else 
                    tail.compareAndSet(last,next);
            }
        }
    }
    public double take(){ 
        while(true){
            Node first = head.get(),
                 last = tail.get(),
                 next = first.next.get();
            if(first == head.get()){
                if(first == last){
                    if(next == null)
                         continue;
                     else 
                        tail.compareAndSet(last,next);
                } else {
                    double result = next.value;
                    if(head.compareAndSet(first,next))
                        return result;
                }
            }
        }
    }
    class Node{
        public final AtomicReference<Node> next;
        public final double value;

        public Node(double value, Node next){
            this.next = new AtomicReference<>(next);
            this.value = value;
        }
    }
}
\end{lstlisting}

\section{}

This code is identical to the original MSQueue except for a \texttt{return null} substituted for a \texttt{continue} in \texttt{take}. I argue that this does not break the correctness of the algorithm (as proved in \cite{michael1996simple}) as it is the same as making two consecutive \texttt{take} calls. \todo[inline]{Maybe elaborate?}

\section{}
\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T22:41:40+0100
Sorting pipe    71.8 ms     2.49    4
\end{lstlisting}

This queue version performs worse than the \texttt{NoLockNDoubleQueue} but better than the so far presented queues. I had expected this queue to be faster than the previous as this is unbounded. This was however not the case. The simplicity of \texttt{NoLockNDoubleQueue} compared to the \texttt{MSUnboundedDoubleQueue} might explain why it performs better.

\chapter{} %10
\section{}
\begin{lstlisting}[caption=Implementation of the \texttt{MSUnboundedDoubleQueue}]
class StmBlockingNDoubleQueue implements BlockingDoubleQueue{
    private final TxnDouble[] arr;
    private final TxnInteger head, tail;

    public StmBlockingNDoubleQueue(){
        arr = new TxnDouble[40];
        for(int i = 0; i < arr.length; i++){
            arr[i] = newTxnDouble(0);
        }
        head = newTxnInteger(0);
        tail = newTxnInteger(0);
    } 

    public void put(double item){
        atomic(() -> {
            if(tail.get() - head.get() == arr.length){
                retry();
            } else {
                arr[tail.get() % arr.length].set(item);
                tail.increment(); 
            } 
        });
    }
    public double take(){ 
        return atomic(() -> {
            if(tail.get() - head.get() == 0) {
                retry();
            } else {
                double item = arr[head.get() % arr.length].get();
                head.increment();
                return item;
            }
            //Needed to compile. Will never be called
            throw new RuntimeException(); 
        });
    }
}
\end{lstlisting}
\section{}
This queue uses transactional memory instead of locking. It is an optimistic approach to concurrency meaning that the system will try to make the desired atomic operation. If it was successful the changes is committed, otherwise the changes are abandoned. It works by recording the state of the `universe'. It then performs the desired operation on the recorded state. If none of the variables was access during the operation the changes are committed, otherwise they are abandoned and the operation is retried. This makes it especially important that the operation has no side effect, like printing to StdOut, as the operation might run multiple times and therefore write to the output multiple times.

I will argue for the correctness of the code above because all operations is done within atomic transactional blocks. Either they succeed because no concurrent write happened in the meantime, or they are retried until successful.

\section{}
\begin{lstlisting}[language={},frame={}]
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T23:18:31+0100
Sorting pipe                        387.5 ms      32.12          2
\end{lstlisting}

This queue implementation is the slowest so far except for the fully synchronized version (\texttt{BlockingNDoubleQueue}). While transactional memory is threadsafe, it is not fast in all cases. In cases with very heavy access to few variables, which is the case here where all methods uses \texttt{tail} and \texttt{head}, a lot of retries might occur.

\chapter{} %11
\chapter{} %12

\chapter*{Example}

This is code in a box

\begin{lstlisting}[caption=This is a caption]
\end{lstlisting}


This is code in the free

\begin{lstlisting}[frame={}]
\end{lstlisting}

\bibliographystyle{plainnat}
\bibliography{bibliography}

\label{LastPage}
\end{document}
