\documentclass{ituhandin}

\coursename{Practical Concurrent and Parallel Programming}
\fullname{Jacob B. Cholewa}
\when{January 2016}
\initials{jbec}
\coursecode{PRCPP}

\begin{document}
\maketitlepage
\signpage

\chapter{} %1

\section{}
The output for \texttt{TestLocking0.java} clearly indicates that it is not thread-safe.
\begin{lstlisting}[language={}, frame={}]
    mac610262:src jbec$ java TestLocking0
    Sum is 1505632.000000 and should be 2000000.000000
    mac610262:src jbec$ java TestLocking0
    Sum is 1490208.000000 and should be 2000000.000000
    mac610262:src jbec$ java TestLocking0
    Sum is 1497894.000000 and should be 2000000.000000
    mac610262:src jbec$ java TestLocking0
    Sum is 1505498.000000 and should be 2000000.000000
\end{lstlisting}

The actual sum deviates from the expected sum leading me to believe that a race condition occurs in the code.

\section{}
The problem is that while the \texttt{addInstance} method locks the object instance, \texttt{addStatic} locks the class. Hence the field \texttt{sum} is guarded by multiple locks. This allows for multiple threads to simultaneously access the \texttt{sum} variable, therefore not upholding mutual exclusion, potentially causing the race condition making it not threadsafe.

\section{}
A simple solution is to change \texttt{addInstance} so that it is guarded by the class lock used by the static synchronized methods
\begin{lstlisting}[frame={}]
    public void addInstance(double x) {
        synchronized(Mystery.class){
            sum += x;
        }
    }
\end{lstlisting}
This now ensures mutual exclusion as \texttt{sum} is now guarded by the same lock. Rerunning the code shows that the expected result and the actual result are now the same.

\begin{lstlisting}[language={}, frame={}]
    mac610262:src jbec$ java TestLocking0
    Sum is 2000000.000000 and should be 2000000.000000
    mac610262:src jbec$ java TestLocking0
    Sum is 2000000.000000 and should be 2000000.000000
    mac610262:src jbec$ java TestLocking0
    Sum is 2000000.000000 and should be 2000000.000000
    mac610262:src jbec$ java TestLocking0
    Sum is 2000000.000000 and should be 2000000.000000
\end{lstlisting}

\chapter{} %2
\section{}
The simplest way would be to make a synchronized version that guards \texttt{items} and \texttt{size} with an instance lock. This would ensure safe concurrent access to the arraylist.
\section{}\label{sec:lock}
While the n√§ive approach described above makes the arraylist threadsafe, it does not allow parallel access and thus doesn't scale. Actually I expect the synchronized version to perform significantly worse when used by many threads compared to only a single thread.
\section{}
A simple answer to why the purposed pattern is not threadsafe is found in the sample given in the assignment. The example clearly shows that both \texttt{add} and \texttt{set} accesses \texttt{items} and \texttt{size}. As the methods uses different locks, concurrent access to \texttt{items} and \texttt{size} can occur making it not threadsafe.

\moreFancyQuote{When thread $A$ executes a synchronized block, and subsequently thread $B$ enters a synchronized block guarded by the same lock, the values of variables that were visible to $A$ prior to releasing the lock are guaranteed to be visible to $B$ upon acquiring the lock.}{\citet[p. 37]{goetz2006java}}

However, because the methods uses different locks, visibility is not guaranteed.
\section{}
While it is possible that a version might exist that makes this threadsafe, it will still require mutual exclusion when at least writing to \texttt{items} and \texttt{size}. I don't see many other (simple) ways than to fully lock both \texttt{items} and \texttt{size} when accessed. Thus it won't make much sense to have a lock for the methods if we either way have to lock the only two shared fields. Then we could as well just only lock those instead.

\chapter{} %3
\section{}
The \texttt{totalSize} field can be made threadsafe by either using an \texttt{AtomicInteger} or by having \texttt{totalSize} guarded by a static lock object. The following snippet shows how it would be implemented in the code using an \texttt{AtomicInteger}

\begin{lstlisting}[frame={}]
    private static AtomicInteger totalSize = new AtomicInteger();

    public boolean add(double x) {
        if (size == items.length) {
            ...
        }
        items[size] = x;
        size++;
        totalSize.incrementAndGet();
        return true;
    }

    public static int totalSize() {
        return totalSize.get();
    }
\end{lstlisting}

\section{}
The \texttt{allLists} field can be make threadsafe by guarding it with a static lock object. It can be implemented in code in following way.
\begin{lstlisting}[frame={}]
    private static HashSet<DoubleArrayList> allLists = new HashSet<>();
    private static Object ListsLock = new Object();

    public DoubleArrayList() {
        synchronized(ListsLock){
            allLists.add(this);
        }
    }

    public static HashSet<DoubleArrayList> allLists() {
        synchronized(ListsLock){
            return allLists;
        }
    }
\end{lstlisting}

\chapter{} %4
\section{}
\begin{lstlisting}[caption=Implemented code for the Sorting stage]
    static class SortingStage implements Runnable {
        private final BlockingDoubleQueue in;
        private final BlockingDoubleQueue out;
        private final double[] heap; 
        private int itemCount;
        private int heapSize = 0;

        public SortingStage(BlockingDoubleQueue in, BlockingDoubleQueue out, int capacity, int itemCount){
            this.in = in;
            this.out = out;
            this.itemCount = itemCount;
            heap = new double[capacity];
        }

        public void run() { 
            while(itemCount > 0){
                double x = in.take();
                if(heapSize < heap.length){ //heap not full, put x into it
                    heap[heapSize++] = x;
                    DoubleArray.minheapSiftup(heap, heapSize-1, heapSize-1);
                } else if (x <= heap[0]){ //x is small, forward
                    out.put(x);
                    itemCount--;
                } else { //forward least, replace with x
                    double least = heap[0];
                    heap[0] = x;
                    DoubleArray.minheapSiftdown(heap,0,heapSize-1);
                    out.put(least);
                    itemCount--;
                }
            }
        }
    }
\end{lstlisting}
See the fully implemented \texttt{SortingPipeline.java} in appendix \todo{make ref}
\newpage
\section{}
\begin{lstlisting}[caption=Implemented code for setting up and starting stages]
    private static void sortPipeline(double[] arr, int P, BlockingDoubleQueue[] queues) {
        int n = arr.length / P;

        //Initializing the sorting stages
        Thread[] threads = new Thread[P+2];
        for(int i = 1; i <= P; i++){
            threads[i-1] = new Thread(new SortingStage(queues[i-1], queues[i], n, arr.length+(P-i)*n)); 
        }

        //Initializing the drain
        threads[P] = new Thread(new SortedChecker(arr.length, queues[P]));

        //Initializing the source. The source is purposefully last in the array so that it will be started lastly.
        threads[P+1] = new Thread(new DoubleGenerator(arr, arr.length, queues[0]));

        //Starting the stages
        for(int i = 0; i < threads.length; i++){
            threads[i].start();
        }

        //Joining the stages
        for(int i = 0; i < threads.length; i++){
            try{ threads[i].join(); }
            catch(InterruptedException e){ throw new RuntimeException(e); }
        }
    }
\end{lstlisting}

\chapter{} %5
\section{} %wrapper
\begin{lstlisting}[caption=Implemented code for wrapping \texttt{ArrayBlockingQueue}]
    class WrappedArrayDoubleQueue implements BlockingDoubleQueue{
        private final ArrayBlockingQueue<Double> queue;

        public WrappedArrayDoubleQueue(){
            this.queue = new ArrayBlockingQueue<Double>(50);
        }

        public WrappedArrayDoubleQueue(int capacity){
            this.queue = new ArrayBlockingQueue<Double>(capacity);
        }

        public void put(double item){
            try{ queue.put(item); }
            catch(InterruptedException e){ throw new RuntimeException(e); }
        }

        public double take(){
            try{ return queue.take(); }
            catch(InterruptedException e){ throw new RuntimeException(e); }
        }
    }
\end{lstlisting}
\section{} %with 40
The result of running the code results in a sorted list of elements as expected. The program terminated by itself indicating that all the stages ended as desired.
\begin{lstlisting}[language={},frame={}]
    mac610262:src jbec$ java SortingPipeline
    0.1 1.1 2.1 3.1 4.1 5.1 6.1 7.1 8.1 9.1 10.1 11.1 12.1 13.1 14.1 15.1 16.1 17.1 18.1 19.1 20.1 21.1 22.1 23.1 24.1 25.1 26.1 27.1 28.1 29.1 30.1 31.1 32.1 33.1 34.1 35.1 36.1 37.1 38.1 39.1
\end{lstlisting}
\section{}\label{sec:sortingpipelinetests}

\todo{write discussion}

\begin{lstlisting}[language={},frame={}]
    mac610262:src jbec$ java SortingPipeline
    # OS:   Mac OS X; 10.11; x86_64
    # JVM:  Oracle Corporation; 1.8.0_60
    # CPU:  null; 8 "cores"
    # Date: 2016-01-11T14:45:02+0100
    Sorting pipe                        125.9 ms       1.71          4
\end{lstlisting}
\chapter{} %6
\section{}

The following queue implementation is a queue inspired by the one presented in the slides from lecture 5 (OneItemQueue), but instead using a cyclic array implemented with a normal array and a \texttt{head} and \texttt{tail} pointer. The pointers will loop back to zero if they get out of bound providing the cyclic behavior.

\begin{lstlisting}[caption= Implementation of the \texttt{BlockingNDoubleQueue} blocking fixed size queue]
class BlockingNDoubleQueue implements BlockingDoubleQueue{

    private final double[] arr = new double[50];
    private int head = 0, tail = 0, count = 0;

    public synchronized void put(double item){
        while(count == arr.length){
            try{ this.wait(); }
            catch(InterruptedException exn) { }
        }

        arr[tail] = item;
        tail = ++tail == arr.length ? 0 : tail;
        count++;
        this.notify();
    }

    public synchronized double take(){
        while(count == 0){
            try{ this.wait(); }
            catch(InterruptedException exn) { }
        }

        double item = arr[head];
        head = ++head == arr.length ? 0 : head;
        count --;
        this.notify();
        return item;
    }
}
\end{lstlisting}

\section{}
The queue presented above is threadsafe as the only two methods, \texttt{put} and \texttt{take} is synchronized. Thus  the array, the two pointers and the counter is guarded by the instance object meaning that only one thread can access them at a time. A thread can be blocked, forced to wait, if the queue is either empty or full. The thread will be forced release the lock and wait until the blocking condition is no longer met. Then the thread will again try to acquire the lock before continuing. This thereby follow the monitor pattern making it threadsafe. 

\section{}
Running the pipeline with the \texttt{BlockingNDoubleQueue} yields following results.
\begin{lstlisting}[language={},frame={}]
    mac610262:src jbec$ java SortingPipeline
    # OS:   Mac OS X; 10.11; x86_64
    # JVM:  Oracle Corporation; 1.8.0_60
    # CPU:  null; 8 "cores"
    # Date: 2016-01-11T16:52:52+0100
    Sorting pipe                        470.4 ms      36.56          2
\end{lstlisting}
These results are quite interesting as it becomes clear that the new queue is a performance bottleneck compared to the results from \ref{sec:sortingpipelinetests} where these results are almost 4 times slower. This might be due to that fact that this queue allows for no parallelism plausibly causing threads to be often blocked by each other.

\chapter{} %7
\section{}
This queue implementation uses a linkedlist to make it unbounded. This means, in contrast to the previous queue, that it can hold as unlimited number of items (while available memory still, of course, is a limitation). This queue is also blocking forcing threads to wait if no elements is available in the queue.
\begin{lstlisting}[caption= Implementation of the \texttt{UnboundedDoubleQueue} blocking queue]
class UnboundedDoubleQueue implements BlockingDoubleQueue{

    public Node head;
    public Node tail;

    public UnboundedDoubleQueue(){
        Node n = new Node(0,null);
        tail = head = n;
    }

    public synchronized void put(double item){
        tail.next = new Node(item,null); //Setting next
        tail = tail.next; //Moving tail

        this.notify(); //Notifying a thread waiting for elements
    }

    public synchronized double take(){
        while(head.next == null){
            try{ this.wait(); }
            catch(InterruptedException exn) { }
        }

        Node first = head;
        head = first.next;
        return head.value;
    }

    class Node{
        public Node next;
        public final double value;

        public Node(double value, Node next){
            this.next = next;
            this.value = value;
        }
    }
}
\end{lstlisting}
\section{}
This implementation also follows the monitor pattern and is therefore threadsafe. In this queue, producers are never forced to wait as the queue is unbounded. Only consumers wait if there is no more elements to consume.
\section{}
\begin{lstlisting}[language={},frame={}]
    mac610262:src jbec$ java SortingPipeline
    # OS:   Mac OS X; 10.11; x86_64
    # JVM:  Oracle Corporation; 1.8.0_60
    # CPU:  null; 8 "cores"
    # Date: 2016-01-11T18:01:39+0100
    Sorting pipe                        262.1 ms      14.29          2
\end{lstlisting}

This queue performs significantly better than the previous. In the previous queue the \texttt{DoubleGenerator}, which will produce faster then the sort stages can consume, was forced to stop and wait for the queue to become non-full. In this queue the \texttt{DoubleGenerator} is never forced to wait which I suspect to be the reason for the vast speedup.

\chapter{} %8
\section{} %8.1
\begin{lstlisting}[caption= Implementation of the \texttt{UnboundedDoubleQueue} blocking queue]
\end{lstlisting}
\section{} %8.2
\section{} %8.3
\section{} %8.4
\section{} %8.5
\section{} %8.6
\begin{lstlisting}[language={},frame={}]
mac610262:src jbec$ java SortingPipeline
# OS:   Mac OS X; 10.11; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 8 "cores"
# Date: 2016-01-11T18:56:06+0100
Sorting pipe                         43.9 ms       1.52          8
\end{lstlisting}
\section{} %8.7
\chapter{} %9
\chapter{} %10
\chapter{} %11
\chapter{} %12

\chapter*{Example}

This is code in a box

\begin{lstlisting}[caption=This is a caption]
\end{lstlisting}


This is code in the free

\begin{lstlisting}[frame={}]
\end{lstlisting}

\bibliographystyle{plainnat}
\bibliography{bibliography}

\label{LastPage}
\end{document}
